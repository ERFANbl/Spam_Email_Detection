{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data Processing**"
      ],
      "metadata": {
        "id": "R7rJraOdzgWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTGBBzP_oshq",
        "outputId": "541848dc-dac8-40e3-b91c-9edbdf2a8f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "popZKrlNyHkH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "stop_words=set(stopwords.words('english'))\n",
        "\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "def process_sentence(sentence):\n",
        "    nouns = list()\n",
        "    base_words = list()\n",
        "    final_words = list()\n",
        "    words_2 = word_tokenize(sentence)\n",
        "    sentence = re.sub(r'[^ \\w\\s]', '', sentence)\n",
        "    sentence = re.sub(r'_', ' ', sentence)\n",
        "    words = word_tokenize(sentence)\n",
        "    pos_tagged_words = pos_tag(words)\n",
        "\n",
        "    for token, tag in pos_tagged_words:\n",
        "        base_words.append(lemmatizer.lemmatize(token,tag_map[tag[0]]))\n",
        "\n",
        "    for word in base_words:\n",
        "        if word not in stop_words:\n",
        "            final_words.append(word)\n",
        "\n",
        "    sym = ' '\n",
        "    sent = sym.join(final_words)\n",
        "    pos_tagged_sent = pos_tag(words_2)\n",
        "\n",
        "    for token, tag in pos_tagged_sent:\n",
        "        if tag == 'NN' and len(token) > 1:\n",
        "            nouns.append(token)\n",
        "\n",
        "    return sent, nouns\n",
        "\n",
        "def clean(email):\n",
        "    email = email.lower()\n",
        "    sentences = sent_tokenize(email)\n",
        "    total_nouns = list()\n",
        "    string = \"\"\n",
        "\n",
        "    for sent in sentences:\n",
        "        sentence, nouns = process_sentence(sent)\n",
        "        string += \" \" + sentence\n",
        "        total_nouns += nouns\n",
        "\n",
        "    return string, nouns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning**"
      ],
      "metadata": {
        "id": "esSEr3GSzq02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "class model:\n",
        "    def __init__(self):\n",
        "        self.df = pd.read_csv('Cleaned_Data.csv')\n",
        "        self.df['label'].replace({\"spam\":1,\"ham\":0},inplace=True)\n",
        "        self.df['Cleaned_Email'] = self.df.Cleaned_Email.apply(lambda email: np.str_(email))\n",
        "        self.Data = self.df.Cleaned_Email\n",
        "        self.Labels = self.df.label\n",
        "        self.training_data, self.testing_data, self.training_labels, self.testing_labels = train_test_split(\n",
        "           self.Data, self.Labels, test_size=0.2, random_state=None, shuffle=True)\n",
        "\n",
        "        self.training_data_list = self.training_data.to_list()\n",
        "        self.testing_data_list = self.testing_data.to_list()\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.training_vectors = self.vectorizer.fit_transform(self.training_data_list)\n",
        "        self.testing_vectors = self.vectorizer.transform(self.testing_data_list)\n",
        "\n",
        "        self.models = {\n",
        "            \"Naive Bayes\": MultinomialNB(),\n",
        "            \"Random Forest\": RandomForestClassifier(n_estimators=19),\n",
        "            \"Logistic Regression\": LogisticRegression(),\n",
        "            \"KNN\": KNeighborsClassifier(n_neighbors=9),\n",
        "            #\"SVM\": SVC(probability=True)\n",
        "        }\n",
        "\n",
        "        self.accuracies = {}\n",
        "        self.weights = {}\n",
        "\n",
        "        for name, clf in self.models.items():\n",
        "            clf.fit(self.training_vectors, self.training_labels)\n",
        "            accuracy = clf.score(self.testing_vectors, self.testing_labels) * 100\n",
        "            self.accuracies[name] = accuracy\n",
        "            print(f\"model {name} accuracy:{accuracy}\")\n",
        "\n",
        "            if accuracy > 95:\n",
        "                self.weights[name] = 3\n",
        "            elif accuracy > 85:\n",
        "                self.weights[name] = 2\n",
        "            else:\n",
        "                self.weights[name] = 1\n",
        "\n",
        "    def get_prediction(self, vector):\n",
        "        spam_counts = 0\n",
        "\n",
        "        for name, clf in self.models.items():\n",
        "            pred = clf.predict(vector)[0]\n",
        "            weight = self.weights[name]\n",
        "\n",
        "            if pred == 1:\n",
        "                spam_counts += weight\n",
        "\n",
        "        if spam_counts >= 6:\n",
        "            return 'Spam'\n",
        "        return 'Non-Spam'\n",
        "\n",
        "    def get_vector(self, text):\n",
        "        return self.vectorizer.transform([text])\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.weights\n"
      ],
      "metadata": {
        "id": "OaENATZ0uzRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"spam_and_ham_classification.csv\")\n",
        "\n",
        "df[\"Cleaned_Email\"], df[\"Extracted_Nouns\"] = zip(*df[\"text\"].apply(clean))\n"
      ],
      "metadata": {
        "id": "xnFtTZIJvMMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"Cleaned_Email\", \"label\"]].to_csv(\"Cleaned_Data.csv\", index=False)"
      ],
      "metadata": {
        "id": "7e2wsynZDqFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ml_model = model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqVQlQMdlLG0",
        "outputId": "68f4b4a1-c216-45c9-b3fd-37334944a366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-e5dc9cf5fbc9>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  self.df['label'].replace({\"spam\":1,\"ham\":0},inplace=True)\n",
            "<ipython-input-6-e5dc9cf5fbc9>:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  self.df['label'].replace({\"spam\":1,\"ham\":0},inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model Naive Bayes accuracy:96.8968968968969\n",
            "model Random Forest accuracy:96.94694694694694\n",
            "model Logistic Regression accuracy:97.2972972972973\n",
            "model KNN accuracy:94.64464464464464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_email = \"\tsteve , sign - off from the research group is something that requires defining formal rules going forward . my concern over the last few years was that we were asked on many occasions to sign - off on partial results of valuation , without the benefits of a full picture . sometimes , we were asked to sign - off on trade ideas , over which we have no control long - term . i shall talk to rick buy and david port about setting up more formal rules for the research sign - off . vince steven leppard 01 / 24 / 2001 03 : 42 am to : sharad agnihotri / lon / ect @ ect cc : tani nath / lon / ect @ ect , ted murphy / lon / ect @ ect , james new / lon / ect @ ect , vince j kaminski / hou / ect @ ect subject : research sign off hi sharad i note from our discussion earlier this morning that you ' ve been asked to sign off a calculation from another group , which is something we ' re asked to do from time to time . i take the view that we in research can assess a computation in terms of what it achieves with respect to its requirements , what its shortfalls are , and therefore what the risks associated with using this method are . we cannot provide an opinion on whether these risks are acceptable to enron , which i feel falls firmly within rac territory . this then raises the question of can research sign off anything for other groups after all ? to \"\" sign off \"\" means to accept something , which our opinion in itself cannot do . it is most appropriate for us to provide a technical note outlining the methodology , risks and shortcomings of a method , leaving the formal \"\" sign off \"\" to those best placed to assess these risks for our company . the alternative is for multiple groups each to have their own view on what is acceptable risk for the company . steve\"\n",
        "cleaned_new_email, _ = clean(new_email)\n",
        "vectorized_email = ml_model.get_vector(cleaned_new_email)\n",
        "prediction = ml_model.get_prediction(vectorized_email)\n",
        "\n",
        "print(f\"Prediction for new email: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SHH0grVIRoz",
        "outputId": "427b3699-edc4-4a43-d1e7-e4a53c41ff7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for new email: Spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jeShlbfFNoBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = ml_model.get_weights()"
      ],
      "metadata": {
        "id": "oC6hL8Apo-yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO_AkT_2yYs1",
        "outputId": "bcc35d75-6c0b-4394-940a-f240808d2dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('Naive Bayes', 3), ('Random Forest', 3), ('Logistic Regression', 3), ('KNN', 2)])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOOi1IaLyc5V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}